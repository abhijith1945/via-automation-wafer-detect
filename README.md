# ğŸ”¬ Virtual Metrology System for Semiconductor Manufacturing

[![Python 3.10+](https://img.shields.io/badge/Python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![Streamlit](https://img.shields.io/badge/Streamlit-1.28+-red.svg)](https://streamlit.io/)
[![TensorFlow](https://img.shields.io/badge/TensorFlow-2.20+-orange.svg)](https://www.tensorflow.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

> **Enterprise-grade AI system for real-time wafer yield prediction, visual defect detection, and self-healing process control in semiconductor fabrication.**

---

## ğŸ“‹ Table of Contents

- [Overview](#-overview)
- [Architecture](#-architecture)
- [Features](#-features)
- [Installation](#-installation)
- [Usage](#-usage)
- [Model Details](#-model-details)
- [Project Structure](#-project-structure)
- [Contributing](#-contributing)

---

## ğŸ¯ Overview

Virtual Metrology (VM) replaces slow, destructive physical measurements with fast, AI-powered predictions. This system demonstrates a **multimodal approach** combining:

1. **Sensor Analytics** - Random Forest on 590 process sensors
2. **Visual Inspection** - CNN-based defect classification
3. **Generative AI** - VAE for synthetic defect image generation
4. **Self-Healing Control** - Feed-forward parameter adjustment

### Business Value

| Metric | Physical Metrology | Virtual Metrology |
|--------|-------------------|-------------------|
| Time per wafer | ~30 minutes | ~0.3 seconds |
| Throughput | 2 wafers/hour | 12,000 wafers/hour |
| **Speedup** | - | **6,000x** |

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    VIRTUAL METROLOGY SYSTEM v3.0                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚   SENSOR     â”‚    â”‚   VISION     â”‚    â”‚  GENERATIVE  â”‚           â”‚
â”‚  â”‚   LAYER      â”‚    â”‚   LAYER      â”‚    â”‚     AI       â”‚           â”‚
â”‚  â”‚              â”‚    â”‚              â”‚    â”‚              â”‚           â”‚
â”‚  â”‚ Random Forestâ”‚â”€â”€â”€â–¶â”‚     CNN      â”‚â”€â”€â”€â–¶â”‚     VAE      â”‚           â”‚
â”‚  â”‚ + SMOTE      â”‚    â”‚  Classifier  â”‚    â”‚   + NLG      â”‚           â”‚
â”‚  â”‚              â”‚    â”‚              â”‚    â”‚              â”‚           â”‚
â”‚  â”‚ 590 sensors  â”‚    â”‚ 4 defect     â”‚    â”‚ Image Gen    â”‚           â”‚
â”‚  â”‚ 93.3% acc    â”‚    â”‚ types        â”‚    â”‚ Report Gen   â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚         â”‚                   â”‚                   â”‚                    â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â”‚                             â”‚                                        â”‚
â”‚                             â–¼                                        â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                  â”‚
â”‚                    â”‚ SELF-HEALING â”‚                                  â”‚
â”‚                    â”‚   CONTROL    â”‚                                  â”‚
â”‚                    â”‚              â”‚                                  â”‚
â”‚                    â”‚ Feed-forward â”‚                                  â”‚
â”‚                    â”‚ parameter    â”‚                                  â”‚
â”‚                    â”‚ adjustment   â”‚                                  â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                  â”‚
â”‚                                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Data Flow

```
Wafer â†’ 590 Sensors â†’ PASS/FAIL prediction
                           â†“
                      If FAIL
                           â†“
                   Visual Inspection â†’ Defect Type
                           â†“
                   Self-Healing â†’ Parameter Correction
```

---

## âœ¨ Features

### ğŸ”¬ Single Wafer Analysis
- Real-time sensor data visualization
- Pass/Fail prediction with confidence scores
- Visual defect classification (Scratch, Edge Ring, Particle)
- Animated self-healing recommendations

### ğŸ“¦ Batch Processing
- CSV upload for bulk analysis
- Progress tracking with yield statistics
- Defect distribution visualization

### ğŸ§¬ Generative AI Lab
- **VAE Image Generator**: Creates synthetic wafer defect images
- **NLG Report Generator**: AI-written defect analysis reports
- Data augmentation for rare defect types

### ğŸ“Š Analytics Dashboard
- SHAP-style feature importance
- Parameter distribution analysis
- Historical trend tracking

### ğŸ“ˆ Model Performance
- ROC and Precision-Recall curves
- Detailed confusion matrix
- Model comparison benchmarks

### ğŸ”„ Auto-Simulation Mode
- Live demo with sensor drift simulation
- Continuous wafer generation for presentations

---

## ğŸš€ Installation

### Prerequisites

- Python 3.10 or higher
- pip (Python package manager)

### Quick Start

```bash
# Clone the repository
git clone https://github.com/abhijith1945/via-automation-wafer-detect.git
cd via

# Create virtual environment
python -m venv .venv

# Activate virtual environment
# Windows:
.venv\Scripts\activate
# Linux/Mac:
source .venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

### Train Models (Optional)

```bash
# Train sensor model (Random Forest + SMOTE)
python train.py

# Train vision model (CNN)
python train_vision_real.py

# Train VAE for image generation
python train_vae.py
```

### Run the Application

```bash
streamlit run app.py
```

Navigate to `http://localhost:8501` in your browser.

---

## ğŸ’» Usage

### Single Wafer Analysis

1. Select **"ğŸ”¬ Single Wafer"** mode
2. Adjust sensor parameters using sliders:
   - Chamber Pressure (90-110 Pa)
   - Etch Temperature (300-600Â°C)
   - Gas Flow Rate (40-60 sccm)
   - RF Power (800-1200 W)
3. Click **"ğŸš€ ANALYZE WAFER"**
4. View prediction results and self-healing recommendations

### Batch Processing

1. Select **"ğŸ“¦ Batch Processing"** mode
2. Upload a CSV with columns: `pressure`, `temperature`, `flow_rate`, `rf_power`
3. Or click **"ğŸ² Generate Demo Batch"** for 20 sample wafers
4. View batch results and yield statistics

### Generative AI

1. Select **"ğŸ§¬ Generative AI"** mode
2. Choose number of images to generate (1-16)
3. Click **"ğŸ¨ Generate Images"** to create synthetic defect images
4. Use **"ğŸ“„ Generate AI Report"** for natural language analysis

### Auto-Simulation (Demo Mode)

1. In Single Wafer mode, check **"ğŸ”„ Auto-Simulate"**
2. Set simulation interval (2-10 seconds)
3. Watch continuous wafer analysis with random sensor drift

---

## ğŸ§  Model Details

### Sensor Model

| Parameter | Value |
|-----------|-------|
| Algorithm | Random Forest Classifier |
| Training Data | UCI SECOM (1,567 samples) |
| Features | 590 sensors |
| Balancing | SMOTE oversampling |
| Accuracy | 93.3% |
| AUC-ROC | 0.94 |

### Vision Model

| Parameter | Value |
|-----------|-------|
| Architecture | CNN (3 Conv layers) |
| Training Data | NEU Surface Defect Database |
| Classes | 4 (Clean, Scratch, Edge Ring, Particle) |
| Input Size | 128Ã—128 pixels |

> âš ï¸ **Note**: Vision model trained on NEU metal surface data as proxy. For production, retrain with actual semiconductor wafer images.

### VAE Generator

| Parameter | Value |
|-----------|-------|
| Architecture | Variational Autoencoder |
| Latent Dimension | 64 |
| Training Epochs | 50 |
| Input/Output | 64Ã—64 RGB images |

---

## ğŸ“ Project Structure

```
via/
â”œâ”€â”€ app.py                  # Main Streamlit dashboard
â”œâ”€â”€ train.py                # Sensor model training
â”œâ”€â”€ train_vision.py         # Vision model training
â”œâ”€â”€ train_vision_real.py    # Vision model (real images)
â”œâ”€â”€ train_vae.py            # VAE training
â”œâ”€â”€ config.py               # Configuration settings
â”œâ”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ README.md               # This file
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data_loader.py      # Data loading utilities
â”‚   â”œâ”€â”€ preprocessing.py    # Data preprocessing
â”‚   â””â”€â”€ llm_reports.py      # NLG report generator
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ yield_model.pkl     # Trained Random Forest
â”‚   â”œâ”€â”€ vision_model.h5     # Trained CNN
â”‚   â”œâ”€â”€ vae_encoder.h5      # VAE encoder
â”‚   â””â”€â”€ vae_decoder.h5      # VAE decoder
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â””â”€â”€ uci-secom.csv   # UCI SECOM dataset
â”‚   â””â”€â”€ processed/          # Preprocessed data
â”‚
â””â”€â”€ assets/
    â”œâ”€â”€ wafer_images/       # Training images (.npy)
    â””â”€â”€ generated_wafers/   # VAE generated images
```

---

## ğŸ“Š Performance Benchmarks

| Operation | Time |
|-----------|------|
| Sensor Prediction | < 20ms |
| Visual Analysis | < 300ms |
| VAE Generation | < 100ms |
| Full Pipeline | < 500ms |

---

## ğŸ¤ Contributing

Contributions are welcome! Please follow these steps:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

---

## ğŸ“œ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- **UCI Machine Learning Repository** - SECOM Dataset
- **NEU Surface Defect Database** - Vision training images
- **Streamlit** - Dashboard framework
- **TensorFlow/Keras** - Deep learning models

---

<div align="center">

**Built with â¤ï¸ for Semiconductor Manufacturing Excellence**

*Virtual Metrology System v3.0 | Enterprise Edition*

</div>
